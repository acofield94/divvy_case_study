---
title: "Untitled"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Exploratory Analysis of Bike-Share Trip Data


## Introduction To Business Problem

Use bicycle share services has grown in cities across the US both as a means of transportation and for exercise. These bikes allow users to pay, use, and return bikes electronically, which means data about bikes, stations, and trips are recorded and stored.

In this case study, I will analyze bike trip data provided from bike-share management company that operates around the US, [Motivate](https://www.motivateco.com/). The ride data I am using is from a bike-share service in Chicago that Motivate operates called Divvy. The data is available for use per this [license](https://www.divvybikes.com/data-license-agreement). For the purpose of this project I will use the name Cyclistic to refer to a fictional company that also operates in Chicago. This fictional company offers three passes to access their bikes: one-time use, single day pass, and an annual membership. One-time and single day passes are considered casual users and customers who purchase annual memberships are referred to as members. In this project I will perform exploratory analysis to bike trip data to understand how casual riders and annual members use Cyclistic bikes differently. The goal of this analysis would be to come up with recommendations for a new marketing strategy to convert casual riders into annual members. 
Then our team will use insights from casual riders vs annual member trends and think about “why would casual riders buy Cyclistic annual memberships?” in order to come up with recommendations for a new marketing strategy to convert casual riders into annual members


## Asking Business Task Centric Questions

Below are some questions that need to be asked regarding the business task.

1. What metrics will I need to compare bike-share users usage?
  - trip duration
  - trip time
  - trip date
  - user type
2. What time frames will I need to analyze?
  - Past 12 months to find any seasonal trends
  - Look at usage per each day of the week to look at weekly trends
3. What tools will I use for data cleaning and analysis?
  
## Collection And Importation Of Data

The raw trip data was made available [here](https://divvy-tripdata.s3.amazonaws.com/index.html). The data is release as csv files one for each month. I used data from the past 12 months each file consist of trip data. The raw contained the following variables:
  - ride_id - to keep track of individual trips taken
  - rideable_type - type of bike used
  - start_at - datetime ride started
  - ended_at - datetime ride ended
  - start_station_name - to identify start station 
  - start_station_id - to identify start station
  - end_station_name - to identify end station
  - end_station_id - to identify end station
  - 4 columns consisting of coordinate data of start and end station
  - member_casual - user type
  
I used RStudio and the tidyverse, lubridate, and ggplot2 packages to import, clean, and aggregate this data. Before the data was imported I checked where the working directory was and then set the working directory to easily access raw data files and eventually save the files of aggregated data.
  
```{r}
library(mrdwabmisc)
library(tidyverse)
library(lubridate)
library(ggplot2)

getwd() #check working directory
setwd("/users/acofi/Documents/Data_Analysis/Cousera/Portfolio & Case Study/Case Study #1") #set working directory

#use read_csv function to import the 12 csv files as dataframes.
`202007` <- read_csv("Raw Data/202007-divvy-tripdata.csv")
`202008` <- read_csv("Raw Data/202008-divvy-tripdata.csv")
`202009` <- read_csv("Raw Data/202009-divvy-tripdata.csv")
`202010` <- read_csv("Raw Data/202010-divvy-tripdata.csv")
`202011` <- read_csv("Raw Data/202011-divvy-tripdata.csv")
`202012` <- read_csv("Raw Data/202012-divvy-tripdata.csv")
`202101` <- read_csv("Raw Data/202101-divvy-tripdata.csv")
`202102` <- read_csv("Raw Data/202102-divvy-tripdata.csv")
`202103` <- read_csv("Raw Data/202103-divvy-tripdata.csv")
`202104` <- read_csv("Raw Data/202104-divvy-tripdata.csv")
`202105` <- read_csv("Raw Data/202105-divvy-tripdata.csv")
`202106` <- read_csv("Raw Data/202106-divvy-tripdata.csv")
```

## Data Inspected For Validity And Merged

Column specifications are listed in the console after each file is imported. This is where I saw that the "station_start_id" and "end_station_id" variable were of the numeric type double for the data files from July 2020 through November 2020. The other 7 files had those two columns as characters. In order to merge all 12 files into one file to clean I converted the any station_id variable that was a numeric vector into a character vector.

The data was then inspected for further quality validity using the str() function and then the rows in all 12 files were merged into a single dataframe.
```{r}


# start_station_id and end_station_id are a double for the first 5 files and they are a character for the rest.
`202007` <- mutate(`202007`, start_station_id = as.character(start_station_id), end_station_id = as.character(end_station_id))
`202008` <- mutate(`202008`, start_station_id = as.character(start_station_id), end_station_id = as.character(end_station_id))
`202009` <- mutate(`202009`, start_station_id = as.character(start_station_id), end_station_id = as.character(end_station_id))
`202010` <- mutate(`202010`, start_station_id = as.character(start_station_id), end_station_id = as.character(end_station_id))
`202011` <- mutate(`202011`, start_station_id = as.character(start_station_id), end_station_id = as.character(end_station_id))


str(`202007`)
str(`202008`)
str(`202010`)
str(`202011`)
str(`202012`)
str(`202101`)
str(`202102`)
str(`202103`)
str(`202104`)
str(`202105`)
str(`202106`)

#combine rows in each dataframe into one dataframe.
all_trips <- bind_rows(`202007`, `202008`, `202009`, `202010`, `202011`, `202012`, `202101`, `202102`, `202103`, `202104`, `202105`, `202106`)
```

## Data Wrangling

Steps in data cleaning process:
  1. Removing columns of data variables that will not be used
    - The four columns on station coordinate data was removed
  2. The single file is further inspected by looking at:
    - column names
    - the number of rows
    - functions to preview data
    - summary() function to look at aggregate summary of values for each variable in the data frame
      > I checked that each character vector had the same length and that
      > the "started_at" variable was within the appropriate ranges of 2020-07-01 to 2021-06-30.
      > The "ended_at" variable was inspected to make sure the min value was after the min value for "started_at".
  3. Columns representing date, month, day, year, and day of the week were added so we can aggregate data on these variable to look for trends in usage.
    - as.Date() was used to convert "start_at" variable to a date and the format() function was used to create the other added variables from the date variable.
  4. A column for the duration of the ride is added called "ride_length". This figure is calculated from the "started_at" and "ended_at" variables and is then converted into a numeric and then divided by 60 to get the ride duration in minutes instead of seconds.
 
  
```{r}
#remove data columns that will not be used 
all_trips <- all_trips %>%
  select(-c(start_lat, start_lng, end_lat, end_lng))

#inspect Data
colnames(all_trips)
nrow(all_trips)
dim(all_trips)
head(all_trips)
str(all_trips)
summary(all_trips)

#add columns for date, month, day, and year for further aggregation
all_trips$date <- as.Date(all_trips$started_at)
all_trips$month <- format(as.Date(all_trips$date), format="%m")
all_trips$day <- format(as.Date(all_trips$date, "%d"))
all_trips$year <- format(as.Date(all_trips$date), "%Y")
all_trips$day_of_week <- format(as.Date(all_trips$date), "%A")

#add "ride_length" calc in minutes and convert the column to numeric for calculations
all_trips$ride_length <-  difftime(all_trips$ended_at, all_trips$started_at)
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))/60


```
  
  5. The updated data frame is then inspected another time to make sure the variable values are in the appropriate constraints for the variable by looking at:
    - A summary of the data variables
      > The minimum value for the "ride_length" is a negative number,
      > so I had to use the filter() function to remove rows that 
      > have ride_length as less than or equal to 0.
    - Unique values of variables "rideable_type", "member_casual", "start_station_name", and "end_station_name" to find any inconsistencies or errors.
      > There were 3 unique values in the "start_station_name" and "end_station_name" columns
      > that were not street intersections nor destinations: 
      > NA, "WATSON TESTING - DIVVY", and "Base - 2132 W Hubbard Warehouse".
  6. Rows where "ride_length" is less than or equal to 0 and rows where the station named matched testing stations that were not used by users were removed.
    - filter() function is used which also removed NA values in those columns filtered out
```{r}
#inspect ranges of ride_length and unique values of character columns to validate data
summary(all_trips)
unique(all_trips$rideable_type)
unique(all_trips$member_casual)
unique(all_trips$start_station_name)

#new version is created where incorrect data where the ride_length is negative and missing(since NA<0 is NA) or where the bikes were checked for quality by Divvy are removed
all_trips_v2 <- all_trips %>%
  filter(!(start_station_name %in% c("WATSON TESTING - DIVVY", 
                                     "HUBBARD ST BIKE CHECKING (LBS-WH-TEST)", 
                                     "Base - 2132 W Hubbard Warehouse") | 
             end_station_name %in% c("WATSON TESTING - DIVVY", 
                                     "HUBBARD ST BIKE CHECKING (LBS-WH-TEST)", 
                                     "Base - 2132 W Hubbard Warehouse") | 
             all_trips$ride_length<=0))
```
  


## Aggregating Data

A quick descriptive analysis of "ride_length" was done to confirm that the column is now within the appropriate constraint of greater than 0 min. Then the "ride_length" is aggregated to compare descriptive statistic of "ride_length" of grouped by user type.

I also created a new data frame that included the number of rides and average ride duration grouped by user type, day, month, and day of the week. I used this data frame of aggregated data as a base data frame to create and plot new data frames that are only grouped by one of the date related variables. I also used this data frame to export to a csv file to further analyze with Tableau. 
```{r}
#descriptive analysis of ride_length
summary(all_trips_v2$ride_length)

#comparing members and casual users ride duration statistics
duration_stats <- aggregate2(all_trips_v2, "ride_length", "member_casual", c("min", "median", "mean", "max"))
duration_stats <- rename(duration_stats,
       min_duration = ride_length.min,
       median_duration = ride_length.median,
       mean_duration = ride_length.mean,
       max_duration = ride_length.max)


#create aggregate data frame grouped by user type, date, month, and day of the week to save for visualization in Tableau to look at quarterly, monthly, and weekday trends
aggregate_by_day  <- all_trips_v2 %>% 
  group_by(member_casual, day, month, day_of_week) %>% #group by user type and day
  summarize(numb_of_rides = n(), #calculate number of rides and average duration
            avg_duration = mean(ride_length)) %>%
  arrange(member_casual, day) #sort  

 #boxplot of avg_duration statistic grouped by user type 
#hiding 3 outlier points for casual members between 250-450 min
ggplot(aggregate_by_day, aes(member_casual, avg_duration)) + geom_boxplot() + coord_cartesian(ylim=c(0, 90))

#export aggregation dfs to csv files
write.csv(aggregate_by_day, file="C:/Users/acofi/Documents/Data_Analysis/Cousera/Portfolio & Case Study/Case Study #1/R_aggregation_day.csv")
```

I found that casual users' average duration spread more than members' average duration. The median casual duration was 79% longer than members and the casual mean was over double that of members. From looking at the boxplot the bottom 25% of data points from casual users is above even some of the outliers for member riders. 


The data frame grouping by only user type and day of week is created and visualized with a bar chart.
```{r}
#aggregate average ride duration and num of rides for each day of week for members vs casual users from aggregate_by_day data frame
aggregation_dayofweek  <- aggregate_by_day %>% 
  group_by(member_casual, day_of_week) %>% #group by usertype and weekday
  summarize(numb_of_rides = sum(numb_of_rides), #calculate number of rides and average duration
            avg_duration = mean(avg_duration)) %>%
  arrange(member_casual, day_of_week) #sort
#visualize the number of rides by rider type and day of week
  ggplot(data=aggregation_dayofweek, aes(x=day_of_week, y=numb_of_rides, fill=member_casual)) + geom_col(position="dodge")
#visualization for average duration
  ggplot(data= aggregation_dayofweek, aes(x=day_of_week, y=avg_duration, fill=member_casual)) + geom_col(position="dodge")

```
FINDINGS:
  1. Average duration for member users was less than half the ride duration of casual users every day of the week. Casual users rider duration peaked during the weekend especially on Saturday.
  2. There is low variation in average duration for members compared to casual users.
  3. The number of rides taken by members peaks on Wednesday.
  4. The number of rides from casual users is lower than members during the work week and is higher on both Saturday and Sunday.
  

A data frame grouping by only user type and month is created and visualized with a line graph which I was able to do with a factor on the x-axis because I put the "member_casual" variable as group and color aethetic. 

```{r}
#aggregate number of rides and average duration each month by user type
  aggregation_month  <- aggregate_by_day %>% 
    group_by(member_casual, month) %>% #group by usertype and month
    summarize(numb_of_rides = sum(numb_of_rides), #calculate number of rides and average duration
              avg_duration = mean(avg_duration)) %>%
    arrange(member_casual, month) #sort
#visualize the number of rides by rider type
ggplot(data=aggregation_month, aes(x=month, y=numb_of_rides, group=member_casual, color=member_casual)) + geom_line()
#visualization for average duration
ggplot(data= aggregation_month, aes(x=month, y=avg_duration, group=member_casual, color=member_casual)) + geom_line()
  
  


```


FINDINGS:
  1. Number of rides for both users types fall as the weather gets colder and peaks during the summer.
  2. There was a spike in average duration for both user types in February. I think this might be related to extreme cold or snowy weather in February 2021. Further analysis is needed to determine relationship.
  3. Average duration fell from over 55 minutes in July to under 30 minutes by October for casual users.
  4. Member average duration was under 20 minutes for all months excepts February 2021.


